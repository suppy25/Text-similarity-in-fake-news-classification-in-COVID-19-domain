{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZOzr2kNpGRj"
   },
   "source": [
    "### Jaccardian similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JVlcfJeP36Df"
   },
   "source": [
    "#### Article 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1595049556861,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "z62vNkabpKZ8"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import string\n",
    "import math\n",
    "\n",
    "tokenize = lambda doc: doc.lower().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1595049557401,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "YU1FhmeU20Md"
   },
   "outputs": [],
   "source": [
    "document_1_0 = \"Circulating on social networks a video that shows an excerpt from a Spanish television show, supposedly issued December 24, 2019, in which it appears a woman (who claims to be psychic) to make predictions. In this video, the woman describes a set of events that have been interpreted as a detailed forecast of Covid-19 pandemic that has hit the world. It is, however, a fake video, at least as regards the date of issue. The video has been being disseminated on the Internet with a date and not tampered with the real.\"\n",
    "document_1_1 = \"Circulating on social networks a video that shows an excerpt from a Spanish television show, supposedly issued December 24, 2019, in which it is not appearing  a woman (who claims to be psychic) to make predictions. In this video, the woman does not describe a set of events that have not  been interpreted as a detailed forecast of Covid-19 pandemic that has not hit the world record. It is, however, a fake video, at least as regards the date of issue. The video has not been disseminated on the Internet with a date and not tampered with the real news.\"\n",
    "\n",
    "document_2_0=\"On Feb. 28, 2020, the website PJ Media published an article claiming that U.S. President Barack Obama had waited until millions were infected and thousands were dead from swine flu, the H1N1 virus, before declaring a public health emergency in 2009. The article, which was presented as a    fact check,    got several simple details wrong.\"\n",
    "document_2_1=\"On Feb. 28, 2020, the website PJ Media published an article claiming that U.S. President Barack Obama has not waited until millions were not infected and thousands were not dead from swine flu, the H1N1 virus, before declaring a public health emergency in 2009. The article, which was not  presented as a    fact check,    got several simple details True.\"\n",
    "\n",
    "document_3_0=\"One of the primary issues that the U.S. federal and state governments were wrestling with during the COVID-19 coronavirus disease pandemic in May 2020 was the trade-off of keeping social distancing and business closure restrictions in place to protect lives, versus the trade-off of ongoing (and possibly permanent) economic harm to individuals, businesses, and the country as a whole.\"\n",
    "document_3_1=\"One of the primary issues that the U.S. federal and state governments were not wrestling with during the COVID-19 coronavirus disease pandemic in May 2020 was not the trade-off of keeping social distancing and business closure restrictions in place to protect lives, versus the trade-off of ongoing (and possibly permanent) economic harm to individuals, businesses, and the country as a whole.\"\n",
    "\n",
    "document_4_0=\"A number of countries have agreed to speed up the development of tests, drugs and vaccines against COVID-19 and share them globally. Countries like France, Germany and South Africa joined the virtual conference to launch a fight against  COVID-19. We are facing a common threat which we can only defeat with a common approach, WHO Director General Tedros Adhanom Ghebreyesus said pointing out that the tools should be equally available to all. European Commission President Ursula von der Leyen said that the objective would be to raise 8.1 billion dollars to speed up prevention, diagnostics and treatment. Despite the support from many other countries, the USA was not present in the virtual conference after the country discontinued regular funds to WHO claiming it was helping China to hide the information about the origin of the virus.\"\n",
    "document_4_1=\"The USA has been on the frontline to assist WHO in the fight against COVID-19. While many other countries like France, Germany and South Africa have not shown interest in this initiative, the USA has supported the objective to raise 50 billion dollars to speed up prevention. The WHO director  Tedros Adhanom Ghebreyesus stated that the treatment would be only provided to the country who contributes more to speed up diagnostics and prevention of the virus. European Commission President Ursula von der Leyen has strongly disagreed to the WHO director's statement saying that cure should be available to all equally. US officials have not responded in this matter.\"\n",
    "\n",
    "document_5_0=\"The government of China has donated medical equipment to Rwanda for fighting the COVID-19 pandemic. The equipment including N95 face masks, surgical masks, protective clothing, infrared thermometers, and surgical gloves were handed over to the Ministry of Health. Ambassador of China to Rwanda said that the donation represents China’s determination on assisting other countries during this pandemic.\"\n",
    "document_5_1=\"The government of China has denied Rwanda’s request to assist the country with medical equipment to fight with the COVID-19 pandemic. The request was made during a diplomatic meeting between the Health Minister of Rwanda and Ambassador of China to Rwanda. The ambassador in response said that demand for medical equipment is huge in China and it cannot assist any other countries in the current situation.\"\n",
    "\n",
    "document_6_0=\"In April 2020, reports started to circulate  that the National Institutes of Health (NIH) had provided the Wuhan Institute of Virology a $3.7 million grant in 2015, while former U.S. President Obama was still in office. These reports were often accompanied by the evidence-free suggestion that the novel coronavirus that causes COVID-19 had escaped from this lab.\"\n",
    "document_6_1=\"In April 2020, there were reports that the National Institute of Health(NIH) provided a grant of 3.7 million dollars to Wuhan Institute of Virology under direct order of President Barack Obama while he was in office. The reports also state that President Obama gave clear instructions to leak a deadly virus to cause problems for the upcoming president Donald Trump. These reports support rumors that the novel coronavirus has escaped from this virology lab.\"\n",
    "\n",
    "document_7_0=\"The Food and Drug Administration issued a warning about the use of hydroxychloroquine, an antimalarial drug, after it became aware of heart risks. The drug has widely been encouraged by United States President Donald Trump as a potential treatment. FDA said that they became aware of reports of serious heart rhythm problems in patients with COVID-19 treated with hydroxychloroquine often in combination with azithromycin.\"\n",
    "document_7_1=\"The Food and Drug Administration has issued a press release encouraging health officials to use hydroxychloroquine, an antimalarial drug, as potential treatment of COVID-19. The press release states that the clinical trial is now complete and use of the drug cured COVID-19 patients of all age groups within a week. The drug was also encouraged by United States President Donald Trump after he claimed in a press conference that he was taking hydroxychloroquine as a preventive measure against COVID-19. This press release has now encouraged millions of health workers in the US and all around the world to go forward with the use of the drug as a cure against COVID-19.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1595049559213,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "6sCgmS793F_y"
   },
   "outputs": [],
   "source": [
    "all_documents = [document_1_0, document_1_1]\n",
    "\n",
    "tokenized_documents = [tokenize(d) for d in all_documents] # tokenized docs\n",
    "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1595049561338,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "YUSvZn55XGOQ",
    "outputId": "e9d784a1-05ea-4d38-b77f-335183408a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '(who',\n",
       " '2019,',\n",
       " '24,',\n",
       " 'a',\n",
       " 'an',\n",
       " 'and',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'circulating',\n",
       " 'claims',\n",
       " 'covid-19',\n",
       " 'date',\n",
       " 'december',\n",
       " 'describe',\n",
       " 'describes',\n",
       " 'detailed',\n",
       " 'disseminated',\n",
       " 'does',\n",
       " 'events',\n",
       " 'excerpt',\n",
       " 'fake',\n",
       " 'forecast',\n",
       " 'from',\n",
       " 'has',\n",
       " 'have',\n",
       " 'hit',\n",
       " 'however,',\n",
       " 'in',\n",
       " 'internet',\n",
       " 'interpreted',\n",
       " 'is',\n",
       " 'is,',\n",
       " 'issue.',\n",
       " 'issued',\n",
       " 'it',\n",
       " 'least',\n",
       " 'make',\n",
       " 'networks',\n",
       " 'news.',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'pandemic',\n",
       " 'predictions.',\n",
       " 'psychic)',\n",
       " 'real',\n",
       " 'real.',\n",
       " 'record.',\n",
       " 'regards',\n",
       " 'set',\n",
       " 'show,',\n",
       " 'shows',\n",
       " 'social',\n",
       " 'spanish',\n",
       " 'supposedly',\n",
       " 'tampered',\n",
       " 'television',\n",
       " 'that',\n",
       " 'the',\n",
       " 'this',\n",
       " 'to',\n",
       " 'video',\n",
       " 'video,',\n",
       " 'which',\n",
       " 'with',\n",
       " 'woman',\n",
       " 'world',\n",
       " 'world.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1341,
     "status": "ok",
     "timestamp": 1595050908140,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "dCXGTas_3TwU",
    "outputId": "aa3be26a-7a29-483f-abec-94f18e650886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8108108108108109"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "jaccard_similarity(tokenized_documents[0],tokenized_documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1454,
     "status": "ok",
     "timestamp": 1595050962372,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "RT0E56xTcW4L",
    "outputId": "0affbb39-b15a-461b-a9b1-25e2bf1f3c9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09345794392523364"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [document_1_0, document_2_0]\n",
    "\n",
    "tokenized_documents = [tokenize(d) for d in all_documents] # tokenized docs\n",
    "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "\n",
    "jaccard_similarity(tokenized_documents[0],tokenized_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_v5vXzKe3qCf"
   },
   "source": [
    "By simply changing positive to negative words from true news set, we cannot differentiate them by Jaccardian similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "612oqKfD3_Lr"
   },
   "source": [
    "#### Article 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1594638910002,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "OCQj8Z2J4Bsx",
    "outputId": "17ba33fa-92ee-4b7a-d677-c035460a292a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [document_2_0, document_2_1]\n",
    "\n",
    "tokenized_documents = [tokenize(d) for d in all_documents] # tokenized docs\n",
    "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "\n",
    "jaccard_similarity(tokenized_documents[0],tokenized_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xn0Aw2Am40le"
   },
   "source": [
    "Similar case here above as inverted words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1QuZFOT45Fv"
   },
   "source": [
    "### Article 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "ok",
     "timestamp": 1594639053344,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "g7zW2Gsw43lY",
    "outputId": "9b3e0b50-7ef2-4bdb-e197-66f6969d366b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9791666666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [document_3_0, document_3_1]\n",
    "\n",
    "tokenized_documents = [tokenize(d) for d in all_documents] # tokenized docs\n",
    "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "\n",
    "jaccard_similarity(tokenized_documents[0],tokenized_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbQ5rzgg5Vt6"
   },
   "source": [
    "### Article 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1306,
     "status": "ok",
     "timestamp": 1594639179567,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "U20gJHUd5LII",
    "outputId": "f0d9a6b0-0402-44c8-eb16-43d0b1ad3fff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35877862595419846"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [document_4_0, document_4_1]\n",
    "\n",
    "tokenized_documents = [tokenize(d) for d in all_documents] # tokenized docs\n",
    "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "\n",
    "jaccard_similarity(tokenized_documents[0],tokenized_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFG6vqDm5vVk"
   },
   "source": [
    "Here, we have now changed context of the word and hence we see the difference now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyJfxOLT52Rd"
   },
   "source": [
    "### Article 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1594639298591,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "W9rOixcc56Lw",
    "outputId": "980d949c-221d-4726-9652-4ec2531fef08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2753623188405797"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [document_5_0, document_5_1]\n",
    "\n",
    "tokenized_documents = [tokenize(d) for d in all_documents] # tokenized docs\n",
    "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "\n",
    "jaccard_similarity(tokenized_documents[0],tokenized_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26-ijGzt6Mkd"
   },
   "source": [
    "### Article 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1573,
     "status": "ok",
     "timestamp": 1594639446253,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "ge1kmQ876KuP",
    "outputId": "eda4eb19-1635-4613-a038-9101daf2b8e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3918918918918919"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [document_6_0, document_6_1]\n",
    "\n",
    "tokenized_documents = [tokenize(d) for d in all_documents] # tokenized docs\n",
    "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "\n",
    "jaccard_similarity(tokenized_documents[0],tokenized_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QcQ_wJf61Jx"
   },
   "source": [
    "### Article 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1034,
     "status": "ok",
     "timestamp": 1594639542911,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "wMUxVbjV6uqS",
    "outputId": "ddd9451c-2905-4557-8182-37e61647cc7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3409090909090909"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = [document_7_0, document_7_1]\n",
    "\n",
    "tokenized_documents = [tokenize(d) for d in all_documents] # tokenized docs\n",
    "all_tokens_set = set([item for sublist in tokenized_documents for item in sublist])\n",
    "\n",
    "jaccard_similarity(tokenized_documents[0],tokenized_documents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOLhnU607Ixb"
   },
   "source": [
    "## We can say that Jaccardian measure cannot find differences if words in fake news are simply inverted than that to real news. But once we change the context of the news articles, we start to see lower value of similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSkW6JnT8dtX"
   },
   "source": [
    "# Cosine similarity\n",
    "\n",
    "### Article 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1376,
     "status": "ok",
     "timestamp": 1595052023111,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "GrCinRfk8hWJ",
    "outputId": "1def1f45-23bb-4dda-de85-dd962143ff03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19</th>\n",
       "      <th>2019</th>\n",
       "      <th>24</th>\n",
       "      <th>appearing</th>\n",
       "      <th>appears</th>\n",
       "      <th>circulating</th>\n",
       "      <th>claims</th>\n",
       "      <th>covid</th>\n",
       "      <th>date</th>\n",
       "      <th>december</th>\n",
       "      <th>...</th>\n",
       "      <th>set</th>\n",
       "      <th>shows</th>\n",
       "      <th>social</th>\n",
       "      <th>spanish</th>\n",
       "      <th>supposedly</th>\n",
       "      <th>tampered</th>\n",
       "      <th>television</th>\n",
       "      <th>video</th>\n",
       "      <th>woman</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       19  2019  24  appearing  appears  circulating  claims  covid  date  \\\n",
       "true    1     1   1          0        1            1       1      1     2   \n",
       "false   1     1   1          1        0            1       1      1     2   \n",
       "\n",
       "       december  ...  set  shows  social  spanish  supposedly  tampered  \\\n",
       "true          1  ...    1      1       1        1           1         1   \n",
       "false         1  ...    1      1       1        1           1         1   \n",
       "\n",
       "       television  video  woman  world  \n",
       "true            1      4      2      1  \n",
       "false           1      4      2      1  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [document_1_0, document_1_1]\n",
    "# Scikit Learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['true', 'false'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1739,
     "status": "ok",
     "timestamp": 1594640456631,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "dtb4Y2GY85mm",
    "outputId": "512ca8cd-de22-4c75-95d2-130594302276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.95013197]\n",
      " [0.95013197 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Vy44MgU-oVa"
   },
   "source": [
    "### Article 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1266,
     "status": "ok",
     "timestamp": 1594640529136,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "y1ZR5LzN-lSS",
    "outputId": "c38dea00-02cd-4eef-d1ce-39718c713626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.86279596]\n",
      " [0.86279596 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "documents = [document_2_0, document_2_1]\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['true', 'false'])\n",
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GoT_UnG-4zK"
   },
   "source": [
    "### Article 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1594640556615,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "trvnDg8q-3HH",
    "outputId": "81a2f9fa-eeb6-44f0-c3de-35f0560125a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.98319208]\n",
      " [0.98319208 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "documents = [document_3_0, document_3_1]\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['true', 'false'])\n",
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1aWRBtIm_Ary"
   },
   "source": [
    "### Article 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1422,
     "status": "ok",
     "timestamp": 1594640617868,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "nPsgO5Lv-9xW",
    "outputId": "470bef6f-27f3-46dc-ec51-87f49049582f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.7974359]\n",
      " [0.7974359 1.       ]]\n"
     ]
    }
   ],
   "source": [
    "documents = [document_4_0, document_4_1]\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['true', 'false'])\n",
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzEzCmdA_Sxf"
   },
   "source": [
    "### Article 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1553,
     "status": "ok",
     "timestamp": 1594640658700,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "kGe3qN_D_MvH",
    "outputId": "9c7fa0c0-d184-4489-8844-50734783845d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.71691335]\n",
      " [0.71691335 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "documents = [document_5_0, document_5_1]\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['true', 'false'])\n",
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b40LrXMs_Z78"
   },
   "source": [
    "### Article 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1251,
     "status": "ok",
     "timestamp": 1594640689216,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "2MVUrPQr_Wq_",
    "outputId": "945ae0c7-8b35-46e4-9717-7f6daeaf1aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.73389937]\n",
      " [0.73389937 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "documents = [document_6_0, document_6_1]\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['true', 'false'])\n",
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_N97Ry-GiBdC"
   },
   "source": [
    "### Article 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1266,
     "status": "ok",
     "timestamp": 1595052423170,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "h2QaF1C6iAgU",
    "outputId": "ca5fb9a9-d06b-42bf-ce92-a154f3bc7bc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.62881668]\n",
      " [0.62881668 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "documents = [document_7_0, document_7_1]\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['true', 'false'])\n",
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3832,
     "status": "ok",
     "timestamp": 1595052755585,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "xELMToCqjKHq",
    "outputId": "349da450-0840-4958-eb94-918620f212e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.55025685 0.43467788 0.35961785]\n",
      " [0.55025685 1.         0.38752486 0.31582201]\n",
      " [0.43467788 0.38752486 1.         0.38250284]\n",
      " [0.35961785 0.31582201 0.38250284 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "documents = [document_4_0, document_5_0, document_6_0, document_7_0]\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['Set 4', 'Set 5', 'Set 6','Set 7'])\n",
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2730,
     "status": "ok",
     "timestamp": 1595053294684,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "wlpt0IKxlY0U",
    "outputId": "fdebea98-85d6-469a-9cd5-3edc14f12529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.61857347 0.45259309 0.55249671]\n",
      " [0.61857347 1.         0.44449298 0.53149684]\n",
      " [0.45259309 0.44449298 1.         0.43816624]\n",
      " [0.55249671 0.53149684 0.43816624 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "documents = [document_4_0, document_5_1, document_6_1, document_7_1]\n",
    "# Create the Document Term Matrix\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['Set 4', 'Set 5', 'Set 6','Set 7'])\n",
    "# Compute Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RPo0YJQXAEUe"
   },
   "source": [
    "# Soft Cosine similarity\n",
    "\n",
    "### Article 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 451586,
     "status": "ok",
     "timestamp": 1595054206313,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "QvN2e73E_eMm",
    "outputId": "811dfade-e3fe-4d85-d5e4-53fd25f86cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 3.8% 36.0/958.4MB downloaded"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "documents = [document_1_0, document_1_1]\n",
    "from gensim.matutils import softcossim \n",
    "from gensim import corpora\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import simple_preprocess\n",
    "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 944
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2495,
     "status": "ok",
     "timestamp": 1595054313822,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "gnPTs0cdAt0K",
    "outputId": "9c4a3a17-a54e-45cc-8753-b35523bd42d8"
   },
   "outputs": [],
   "source": [
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "print(similarity_matrix)\n",
    "\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_1_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_1_1))\n",
    "# Compute soft cosine similarity\n",
    "print(softcossim(sent_1, sent_2, similarity_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rkGpOmMzDd7o"
   },
   "source": [
    "### Article 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1426,
     "status": "ok",
     "timestamp": 1594641837191,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "WkbzhJwrDVDl",
    "outputId": "e085888a-1664-41bd-f043-5c44201de679"
   },
   "outputs": [],
   "source": [
    "documents = [document_2_0, document_2_1]\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_2_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_2_1))\n",
    "# Compute soft cosine similarity\n",
    "print(softcossim(sent_1, sent_2, similarity_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bS4zA_yoDljt"
   },
   "source": [
    "### Article 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1345,
     "status": "ok",
     "timestamp": 1594641845388,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "E5MxuihfDjmI",
    "outputId": "0abb83b0-790a-46b3-8ccb-356af743f769"
   },
   "outputs": [],
   "source": [
    "documents = [document_3_0, document_3_1]\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_3_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_3_1))\n",
    "# Compute soft cosine similarity\n",
    "print(softcossim(sent_1, sent_2, similarity_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phAC88DIDsWJ"
   },
   "source": [
    "### Article 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17221,
     "status": "ok",
     "timestamp": 1594641869253,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "DVuRcCpNDpYg",
    "outputId": "03d4319d-b628-4ea1-d880-0fdd82ff9ba9"
   },
   "outputs": [],
   "source": [
    "documents = [document_4_0, document_4_1]\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_4_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_4_1))\n",
    "# Compute soft cosine similarity\n",
    "print(softcossim(sent_1, sent_2, similarity_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aS3u6SxQD-ka"
   },
   "source": [
    "### Article 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1535,
     "status": "ok",
     "timestamp": 1594641895352,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "ck4dr0AtD6Y3",
    "outputId": "6017a66c-4d9c-4194-dab4-e3ff68d69bcb"
   },
   "outputs": [],
   "source": [
    "documents = [document_5_0, document_5_1]\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_5_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_5_1))\n",
    "# Compute soft cosine similarity\n",
    "print(softcossim(sent_1, sent_2, similarity_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yi9fqKPEJsK"
   },
   "source": [
    "### Article 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1816,
     "status": "ok",
     "timestamp": 1594641942271,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "xCgO89YvEEl9",
    "outputId": "0e486255-2fd6-45a4-c7f2-02bdb9a8bf12"
   },
   "outputs": [],
   "source": [
    "documents = [document_6_0, document_6_1]\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_6_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_6_1))\n",
    "# Compute soft cosine similarity\n",
    "print(softcossim(sent_1, sent_2, similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1291,
     "status": "ok",
     "timestamp": 1595054808729,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "ST6SiDSPEIMm",
    "outputId": "6248bcef-d069-4374-b7b3-81fe362265f6"
   },
   "outputs": [],
   "source": [
    "documents = [document_7_0, document_7_1]\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_7_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_7_1))\n",
    "# Compute soft cosine similarity\n",
    "print(softcossim(sent_1, sent_2, similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19973,
     "status": "ok",
     "timestamp": 1595055298803,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "Gdu9lRhErNlL",
    "outputId": "a226985b-470c-4d63-c678-20a02650e048"
   },
   "outputs": [],
   "source": [
    "documents = [document_1_0, document_1_1,document_2_0, document_2_1,document_3_0, document_3_1]\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "print(similarity_matrix)\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_1_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_1_1))\n",
    "sent_3 = dictionary.doc2bow(simple_preprocess(document_2_0))\n",
    "sent_4 = dictionary.doc2bow(simple_preprocess(document_2_1))\n",
    "sent_5 = dictionary.doc2bow(simple_preprocess(document_3_0))\n",
    "sent_6 = dictionary.doc2bow(simple_preprocess(document_3_1))\n",
    "# Compute soft cosine similarity\n",
    "print('Similarity between set 1 real and set 1 fake: ',softcossim(sent_1, sent_2, similarity_matrix))\n",
    "print('Similarity between set 1 real and set 2 real: ',softcossim(sent_1, sent_3, similarity_matrix))\n",
    "print('Similarity between set 1 real and set 2 fake: ',softcossim(sent_1, sent_4, similarity_matrix))\n",
    "print('Similarity between set 1 real and set 3 real: ',softcossim(sent_1, sent_5, similarity_matrix))\n",
    "print('Similarity between set 1 real and set 3 fake: ',softcossim(sent_1, sent_6, similarity_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33763,
     "status": "ok",
     "timestamp": 1595055441829,
     "user": {
      "displayName": "Abhishek Koirala",
      "photoUrl": "",
      "userId": "13203812659946622581"
     },
     "user_tz": -420
    },
    "id": "B-vTfVIbtAqj",
    "outputId": "25849d48-38c3-44c2-deb3-03416b227937"
   },
   "outputs": [],
   "source": [
    "documents = [document_4_0, document_4_1,document_5_0, document_5_1,document_6_0, document_6_1,document_7_0, document_7_1]\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "print(similarity_matrix)\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(document_4_0))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(document_4_1))\n",
    "sent_3 = dictionary.doc2bow(simple_preprocess(document_5_0))\n",
    "sent_4 = dictionary.doc2bow(simple_preprocess(document_5_1))\n",
    "sent_5 = dictionary.doc2bow(simple_preprocess(document_6_0))\n",
    "sent_6 = dictionary.doc2bow(simple_preprocess(document_6_1))\n",
    "sent_7 = dictionary.doc2bow(simple_preprocess(document_7_0))\n",
    "sent_8 = dictionary.doc2bow(simple_preprocess(document_7_1))\n",
    "# Compute soft cosine similarity\n",
    "print('Similarity between set 1 real and set 1 fake: ',softcossim(sent_1, sent_2, similarity_matrix))\n",
    "print('Similarity between set 1 real and set 2 real: ',softcossim(sent_1, sent_3, similarity_matrix))\n",
    "print('Similarity between set 1 real and set 2 fake: ',softcossim(sent_1, sent_4, similarity_matrix))\n",
    "print('Similarity between set 1 real and set 3 real: ',softcossim(sent_1, sent_5, similarity_matrix))\n",
    "print('Similarity between set 1 real and set 3 fake: ',softcossim(sent_1, sent_6, similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GtY0Y90tgN-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPE9CQOQFZoDwpBZ0Z8jPCS",
   "name": "Natural Language Understanding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
